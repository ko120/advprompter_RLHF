defaults:
  - base_value
  - _self_

llm_params:
  model_name: "harm_bench_Llama_4bit"
  checkpoint: "RichardErkhov/cais_-_HarmBench-Llama-2-13b-cls-4bits"
  quantization:
    type: "load_in_4bit"
    bnb_4bit_quant_type: "nf4"
    bnb_4bit_use_double_quant: True
  lora_params:
    warmstart: false
    lora_checkpoint: null
    lora_config:
      r: 8
      lora_alpha: 16
      bias: "none"
      target_modules:
        - q_proj
        - v_proj
        - score # using score only doesn't increase overal reward
      task_type: "SEQ_CLS"
prompt_manager: # use same prompt template for target llm since input prompt would be full_instruct
  prompt_template:
    - key: system_message
      msg: "<s>[INST]"
    - key: full_instruct
      msg: "{full_instruct}"  # loaded from context
    - key: separator
      msg: "[/INST]"
    - key: target
      msg: "{target}"  # loaded from context