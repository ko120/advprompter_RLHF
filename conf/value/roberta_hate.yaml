defaults:
  - base_value
  - _self_

llm_params:
  model_name: "roberta-hate-speech"
  checkpoint: 'facebook/roberta-hate-speech-dynabench-r4-target'
  classification: true
  quantization:
    type: "load_in_4bit"
    bnb_4bit_quant_type: "nf4"
    use_bnb_nested_quant: false
  lora_params:
    warmstart: false
    lora_checkpoint: null
    lora_config:
      r: 8
      lora_alpha: 16
      bias: "none"
      target_modules:
        - lm_head
      task_type: "SEQ_CLS"
prompt_manager:
  prompt_template: 
    - key: system_message
      msg: "<s>"
    - key: hyper_instruct
      msg: "{instruct}"  # loaded from context
    - key: suffix
      msg: "{suffix}"  # loaded from context